## 实时计算flink
>看完 [Flink 从 0 到 1 学习 —— Apache Flink 介绍](http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/), 突然觉得跟自己之前
接触的业务场景比较相似，都是根据数据做聚合，超过阈值，做出告警处理。 只是处理方式不一样，开启阈值开关，然后将数据聚集起来。
比如统计当前批次数据中每个人财务收入情况，数据量可达到十万、百万、千万、亿级别。

之前处理场景，从es中把数据拷贝下来，短信收入需要NLP提词，然后转存到mysql中，其他的交易记录表数据需要转存到mysql, 然后对这些数据
拉取，在内存做聚集操作，然后就可以实现统计汇总，根据阈值与汇总的数据做对比，然后就可以展示。

思考的问题， 1. 数据量多少， 2. 计算时间多少  3. 数据量会不会增加
数据量之前为几十万-百万，  计算时间估计3-4分钟， 后期数据量会不断增加，只是这些都是分不同的维度，当前一个维度的数据量就是百万

如果这个维度的数据上了百万-千万，估计计算时间很长。
如果数据中某个数据发生变化， 如何准确计算

有必要做下总结， 链接中描述实时计算的框架为 所有的监控数据从采集、采集后的数据做一些 计算/转换/聚合、再通过 Kafka 消息队列、再存进 ElasticSearch 中，再而去 ElasticSearch 中查找我们的监控数据，然后做出告警策略。
整个流程对监控来说看起来很按照常理，但是对于告警来说，如果中间某个环节出了问题，比如 Kafka 消息队列延迟、监控数据存到 ElasticSearch 中写入时间较长、你的查询方式写的不对等原因，这都将导致告警从 ElasticSearch 查到的数据是有延迟的。也许是 30 秒、一分钟、或者更长，这样对于告警来说这无疑将导致告警的消息没有任何的意义。

为什么需要监控告警平台呢？无非就是希望我们能够尽早的发现问题，把问题给告警出来，这样开发和运维人员才能够及时的处理解决好线上的问题。

更何况现在还有更多的公司在做那种提前预警呢！

需要用大数据和机器学习的技术去分析周期性的历史数据，然后根据这些数据可以整理出来某些监控指标的一些周期性（一天/七天/一月/一季度/一年）
走势图，这样就大概可以绘图出来。然后根据这个走势图，可以将当前时间点的监控指标的数据使用量和走势图进行对比，在快要达到我们告警规则的
阈值时，这时就可以提前告一个预警出来，让运维提前知道预警，然后提前查找问题，这样就能够提早发现问题所在，避免损失，将损失降到最小！
当然，这种也是我打算做的，应该可以学到不少东西的。





>http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/
