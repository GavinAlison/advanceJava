## es的集群原理
Zen发现机制
Zen发现是ES自带的默认发现机制，使用多播发现其它节点。只要启动一个新的ES节点并设置和集群相同的名称这个节点就会被加入到集群中
es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。

es是基于p2p的系统，各个节点之间直接交互。所有的主要API操作（index、delete、search）都不会和主节点交流。主节点只负责维护全局的集群状态。

zen发现模块可以细分以下几块：
l  Ping-多播
这是一个节点通过发现机制查找其他节点的进程
2  Unicast-单播
单播发现需要一组主机列表来充当gossip routers，这些主机可以提供主机名称或者主机的IP；
当在Ping的过程中，提供名称的主机被解析成IP地址。需要注意的是你的环境中如果DNS解析如果随着时间变化的话，你需要调整JVMsecurity settings.


## ElasticSearch基本概念
1、索引(Index): 
2、类型(Type)：  
3、文档(Document)：  
4、字段(Field)：
5、映射(Mapping):  

## 功能特点
1、分布式的搜索引擎和数据分析引擎；
2、全文检索、结构化检索、数据分析；
3、对海量数据进行近实时处理；

## 应用场景
1、站点全文搜索检索引擎（Stack Overflow，Github）;
2、实时日志检索系统（ElasticSearch+LogStash+Kibana）;
3、实时在线分析系统（OLAP）；
4、实时推荐系统；

## 整体架构
1、一个集群由多个具有相同集群名称的节点组成；
2、一个索引由多个shard组成，分为primary shard和replica shard，这些shard分布在不同的节点上；
3、每个shard都是独立的Lucene实例，支持写入和查询操作。

## 单个ElasticSearch节点的内部架构
1、节点与节点之间通过Transport模块互相通信，通过Discovery模块互相发现；
2、通过GateWay模块进行持久化存储；
3、对外RestfulAPI层，脚本编译执行层、索引模块、查询模块

## ElasticSearch索引文档的过程
1、先根据文档id确定shard编号，在根据集群路由表，转发该请求到指定shard所在的节点。(all,one,quorum模式)；
2、在节点上，先将文档内容写入到内存buffer中，同时记录translog日志，当内存buffer满时，会刷写到文件系统缓存中，Lucene就可以检索这个新的segment了。

也可以具体化为如下的过程：
A、先根据文档id进行get查询：先根据文档id确定shard编号，再根据集群路由表，到对应的primary shard和replica shard所在的节点上进行查找，如果在segment中未找到，则在translog中进行查找；

B、再根据查询条件search查询：索引的primary shard和replica shard所在的节点进行检索，将检索到的结果返回给协调节点，协调节点将各个响应结果合并返回给客户端。

## 查询原理
1、倒排索引：单词到文档id的映射；
2、正排索引：文档id到单词的映射；
3、有多个查询条件时，会使用bitset来保存某个查询条件的文档id，最终多个bitset计算得到最终符合条件的文档id。

## Elasticsearch更新和删除文档的过程
1、更新：先在primary shard找到文档的_source字段的Json进行更新操作，更新完成后，转发新文档到replica shard，最终返回客户端。
更新文档会首先查找原文档，得到该文档的版本号。然后将修改后的文档写入内存，此过程与写入一个新文档相同。同时，旧版本文档被标记为删除，同理，该文档可以被搜索到，只是最终被过滤掉。


2、删除：找到对应的primary shard和replica shard节点，把文档id值加入.del文件，查询操作时会排除在.del文件中的文档
每一个磁盘上的segment都会维护一个del文件，用来记录被删除的文件。每当用户提出一个删除请求，文档并没有被真正删除，索引也没有发生改变，而是在del文件中标记该文档已被删除。因此，被删除的文档依然可以被检索到，只是在返回检索结果时被过滤掉了。每次在启动segment合并工作时，那些被标记为删除的文档才会被真正删除。

## 数据写入的底层原理：
1. 每次写入新文档时，都会先写入内存buffer中，并将这一操作写入一个translog文件（transaction log）中。此时如果执行搜索操作，这个新文档还不能被索引到。
2. 当buffer中有数据，ES默认每隔1秒时间（这个时间可修改）进行一次refresh操作。此时在这1秒内写入buffer的文档会被写入一个文件系统缓存
（filesystem cache）中，并构成一个分段（segment），然后清空buffer。此时这个segment里的文档可以被搜索到，
但是尚未写入硬盘，即如果此时发生断电，则这些文档可能会丢失。 （过程1~2叫refresh）
3. 不断有新的文档写入，则过程1~2不断重复执行。每隔一秒生成一个新的segment，而translog文件将越来越大。
4. 每隔30分钟或者translog文件变得很大，则执行一次fsync操作。此时立刻执行一次refresh操作，然后将所有在文件系统缓存中的segment写入磁盘，而translog将被删除（此后会生成新的translog）。 （此过程叫flush）

由上面的流程可以看出，在两次fsync操作之间，存储在内存和文件系统缓存中的文档是不安全的，一旦出现断电这些文档就会丢失。所以ES引入了translog来记录两次fsync之间所有的操作，这样机器从故障中恢复或者重新启动，ES便可以根据translog进行还原。

当然，translog本身也是文件，存在于内存当中，如果发生断电一样会丢失。但是，ES会在每隔5秒时间或是一次写入请求完成后将translog写入磁盘。可以认为一个对文档的操作一旦写入磁盘便是安全的可以复原的，因此只有在当前操作记录被写入磁盘，ES才会将操作成功的结果返回发送此操作请求的客户端。

此外，由于每一秒就会生成一个新的segment，很快将会有大量的segment。对于一个分片进行查询请求，将会轮流查询分片中的所有segment，这将降低搜索的效率。因此ES会自动启动合并segment的工作，将一部分相似大小的segment合并成一个新的大segment。合并的过程实际上是创建了一个新的segment，当新segment被写入磁盘，所有被合并的旧segment被清除。

## 提高性能
如果数据频繁的更新，查询性不可重复（比如日志量更新量很大，不断查询最近15分钟日志），其实缓存的价值并不是很大；
对于内存压力很大的排序，汇总等处理，使用docValues来进行数据的字段级别的缓存，他占用极少的内存；
建议关闭Unix的内存关闭，bootstrap.mlockall=true；
热点线程：`_nodes/hot_threads`；可以获取那些占用了大量内存和cpu的线程，可以指定返回的条数，另外返回的内容不是json，而是一段组织好的文本；
扩展ES：有水平和垂直两种，重点说一下垂直。两种方式：多分片和多副本；如果瓶颈在于硬盘不够了，那么增加分片，做存储的负载均衡；如果瓶颈在于查询的压力，那么增加副本做请求的负载均衡；
关于副本，ES提供了一种自动创建副本的机制，就是实现某些索引的数据自动在所有的节点进行部署副本，这类数据首先是别频发使用的，比如基础数据，另外就是占用空间不能太大，否则每个节点都部署，存储压力会很大。

## 提高新能之对于高负载的场景：
存储使用default，
考虑延长刷新时间，默认是1s，设置为`10s~30s`，减少I/O压力；
优化线程池，注意大多数情况下默认配置是OK的，当且仅当主机计算能力有富余，同时操作有队列（有积压）的情况下，需要考虑调整线程池；
控制合并过程，主要控制段（segment）的大小，段是Lucene里面的物理存储单元，段越小，导致段很多，会导致查询变慢，内存使用量增加，但是索引会变得很快；如果你希望加快查询那么控制段的大小在一个相对较大的程度，这样会减少段的数量；
限流，可以控制I/O流量；
分布式，通过分布式，比如分片来减轻存储的压力；

## 提高性能之对于高频查询的场景：
尽量多利用缓存，比如过滤器缓存（倒排索引），分片缓存（非倒排索引）；
使用路由；减少因为合并各方数据浪费的时间；

## 提高性能之对于高索引场景：
批量索引，注意控制段的大小，不要过大。



## 倒排索引
1. 一个文本通过分词，形成单词-位置的映射，一个单词，多个位置的映射。
跟位置-单词的映射类型的索引是不一致的。


